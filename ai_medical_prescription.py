# -*- coding: utf-8 -*-
"""AI medical prescription.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iVzGn1oev5EdSKjLymGvcET67WXNHy8M
"""

# ======================================================
# AI MEDICAL PRESCRIPTION SYSTEM (ONE-CELL COLAB SCRIPT)
# ======================================================

# ----------------------------
# Install dependencies
# ----------------------------
!pip install transformers==4.42.0 accelerate torch torchvision torchaudio gradio

# ----------------------------
# Imports
# ----------------------------
import gradio as gr
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

# ----------------------------
# Load IBM Granite 3.3 2B Instruct
# ----------------------------
model_name = "ibm-granite/granite-3.3-2b-instruct"

tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.float16,
    device_map="auto"
)

# ----------------------------
# Text Generation Helper
# ----------------------------
def generate(prompt):
    inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
    output = model.generate(
        **inputs,
        max_new_tokens=300,
        temperature=0.3
    )
    return tokenizer.decode(output[0], skip_special_tokens=True)

# ----------------------------
# 1. Patient Details Processing
# ----------------------------
def process_patient_details(text):
    prompt = f"""
    Analyze the following patient details and provide a clear summary.
    DO NOT provide medical advice or diagnosis.

    Patient details:
    {text}

    Provide:
    - Clean structured summary
    - Missing important details
    - Helpful suggestions for clarity (non-medical)
    - Disclaimer: "Not medical advice."
    """
    return generate(prompt)

# ----------------------------
# 2. Medical Prescription Details Processing
# ----------------------------
def process_prescription(text):
    prompt = f"""
    Analyze the following medical prescription information.
    DO NOT provide medical judgement or advice.

    Prescription text:
    {text}

    Provide:
    - Identified medicine names
    - Detected dosage/frequency format clarity
    - Missing or unclear info
    - General formatting improvements
    - Safety disclaimer: "This is not medical advice."
    """
    return generate(prompt)

# ----------------------------
# 3. Real-Time Feedback (AI Chat)
# ----------------------------
def real_time_feedback(user_input):
    prompt = f"""
    You are an AI assistant giving general informational feedback
    (not medical advice).

    User message:
    {user_input}

    Provide:
    - Helpful suggestions
    - Communication improvements
    - Data organization tips
    - Clear and concise response
    - Disclaimer: "Not medical guidance."
    """
    return generate(prompt)

# ----------------------------
# Gradio UI
# ----------------------------
with gr.Blocks() as ui:
    gr.Markdown("""
    # üè• AI Medical Prescription Assistant
    ### Powered by IBM Granite 3.3 2B Instruct
    **Educational purposes only ‚Äî NOT medical advice.**
    """)

    with gr.Tab("üìã Patient Details"):
        p_input = gr.Textbox(lines=8, label="Enter Patient Details")
        p_output = gr.Textbox(label="Processed Patient Summary")
        p_button = gr.Button("Process")
        p_button.click(process_patient_details, inputs=p_input, outputs=p_output)

    with gr.Tab("üíä Prescription Details"):
        r_input = gr.Textbox(lines=8, label="Enter Prescription Details")
        r_output = gr.Textbox(label="Processed Prescription Analysis")
        r_button = gr.Button("Analyze")
        r_button.click(process_prescription, inputs=r_input, outputs=r_output)

    with gr.Tab("‚ö° Real-Time Feedback"):
        f_input = gr.Textbox(lines=5, label="Ask Anything (non-medical)")
        f_output = gr.Textbox(label="AI Response")
        f_button = gr.Button("Get Feedback")
        f_button.click(real_time_feedback, inputs=f_input, outputs=f_output)

# Launch App
ui.launch()

# ======================================================
# AI MEDICAL PRESCRIPTION SYSTEM (ONE-CELL COLAB SCRIPT)
# ======================================================

# ----------------------------
# Install dependencies
# ----------------------------
!pip install transformers==4.42.0 accelerate torch torchvision torchaudio gradio

# ----------------------------
# Imports
# ----------------------------
import gradio as gr
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

# ----------------------------
# Load IBM Granite 3.3 2B Instruct
# ----------------------------
model_name = "ibm-granite/granite-3.3-2b-instruct"

tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.float16,
    device_map="auto"
)

# ----------------------------
# Text Generation Helper
# ----------------------------
def generate(prompt):
    inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
    output = model.generate(
        **inputs,
        max_new_tokens=300,
        temperature=0.3
    )
    return tokenizer.decode(output[0], skip_special_tokens=True)

# ----------------------------
# 1. Patient Details Processing
# ----------------------------
def process_patient_details(text):
    prompt = f"""
    Analyze the following patient details and provide a clear summary.
    DO NOT provide medical advice or diagnosis.

    Patient details:
    {text}

    Provide:
    - Clean structured summary
    - Missing important details
    - Helpful suggestions for clarity (non-medical)
    - Disclaimer: "Not medical advice."
    """
    return generate(prompt)

# ----------------------------
# 2. Medical Prescription Details Processing
# ----------------------------
def process_prescription(text):
    prompt = f"""
    Analyze the following medical prescription information.
    DO NOT provide medical judgement or advice.

    Prescription text:
    {text}

    Provide:
    - Identified medicine names
    - Detected dosage/frequency format clarity
    - Missing or unclear info
    - General formatting improvements
    - Safety disclaimer: "This is not medical advice."
    """
    return generate(prompt)

# ----------------------------
# 3. Real-Time Feedback (AI Chat)
# ----------------------------
def real_time_feedback(user_input):
    prompt = f"""
    You are an AI assistant giving general informational feedback
    (not medical advice).

    User message:
    {user_input}

    Provide:
    - Helpful suggestions
    - Communication improvements
    - Data organization tips
    - Clear and concise response
    - Disclaimer: "Not medical guidance."
    """
    return generate(prompt)

# ----------------------------
# Gradio UI
# ----------------------------
with gr.Blocks() as ui:
    gr.Markdown("""
    # üè• AI Medical Prescription Assistant
    ### Powered by IBM Granite 3.3 2B Instruct
    **Educational purposes only ‚Äî NOT medical advice.**
    """)

    with gr.Tab("üìã Patient Details"):
        p_input = gr.Textbox(lines=8, label="Enter Patient Details")
        p_output = gr.Textbox(label="Processed Patient Summary")
        p_button = gr.Button("Process")
        p_button.click(process_patient_details, inputs=p_input, outputs=p_output)

    with gr.Tab("üíä Prescription Details"):
        r_input = gr.Textbox(lines=8, label="Enter Prescription Details")
        r_output = gr.Textbox(label="Processed Prescription Analysis")
        r_button = gr.Button("Analyze")
        r_button.click(process_prescription, inputs=r_input, outputs=r_output)

    with gr.Tab("‚ö° Real-Time Feedback"):
        f_input = gr.Textbox(lines=5, label="Ask Anything (non-medical)")
        f_output = gr.Textbox(label="AI Response")
        f_button = gr.Button("Get Feedback")
        f_button.click(real_time_feedback, inputs=f_input, outputs=f_output)

# Launch App
ui.launch()



# ============================
# AI MEDICAL PRESCRIPTION PROJECT
# Single-Cell Code for Google Colab
# Using IBM Granite 3.3 2B Instruct & Gradio UI
# ============================

!pip install -q transformers accelerate torch gradio

import gradio as gr
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# ============================
# Load IBM Granite 3.3 2B Instruct Model
# ============================
model_name = "ibm-granite/granite-3.3-2b-instruct"

tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.float16,
    device_map="auto"
)

# ============================
# Function to generate AI responses
# ============================
def generate_response(prompt):
    inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
    outputs = model.generate(**inputs, max_new_tokens=250)
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    return response

# ============================
# MAIN APP LOGIC
# ============================

def ai_medical_system(name, age, gender, symptoms, medical_history, allergies):
    # Build patient summary
    patient_info = f"""
    Patient Name: {name}
    Age: {age}
    Gender: {gender}
    Symptoms: {symptoms}
    Medical History: {medical_history}
    Allergies: {allergies}
    """

    # --- 1. PRESCRIPTION GENERATION ---
    prescription_prompt = f"""
    You are an AI medical assistant.
    Based on the following patient details, generate a safe, structured medical prescription.
    Avoid controlled drugs. Include dosage, timing, precautions, and lifestyle advice.

    {patient_info}

    Prescription:
    """
    prescription = generate_response(prescription_prompt)

    # --- 2. REAL-TIME AI FEEDBACK ---
    feedback_prompt = f"""
    You are a clinical AI system.
    Review the following prescription and give safety feedback, warnings, and suggestions.
    Be concise and medically appropriate.

    Prescription:
    {prescription}
    """
    feedback = generate_response(feedback_prompt)

    return prescription, feedback


# ============================
# GRADIO USER INTERFACE
# ============================

with gr.Blocks(title="AI Medical Prescription System") as app:
    gr.Markdown("# üè• AI Medical Prescription System\nUsing IBM Granite 3.3 2B Instruct")

    with gr.Row():
        name = gr.Textbox(label="Patient Name")
        age = gr.Number(label="Age")
        gender = gr.Radio(["Male", "Female", "Other"], label="Gender")

    symptoms = gr.Textbox(label="Symptoms", lines=3)
    medical_history = gr.Textbox(label="Medical History", lines=3)
    allergies = gr.Textbox(label="Allergies", lines=2)

    generate_btn = gr.Button("Generate Prescription")

    prescription_output = gr.Textbox(label="AI-Generated Prescription", lines=10)
    feedback_output = gr.Textbox(label="AI Feedback & Safety Review", lines=10)

    generate_btn.click(
        ai_medical_system,
        inputs=[name, age, gender, symptoms, medical_history, allergies],
        outputs=[prescription_output, feedback_output]
    )

app.launch()



# ============================
# AI MEDICAL PRESCRIPTION PROJECT (FIXED TOKENIZER VERSION)
# Single-Cell Code for Google Colab
# Using IBM Granite 3.3 2B Instruct & Gradio UI
# ============================

!pip install -q transformers accelerate torch gradio sentencepiece

import gradio as gr
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# ============================
# Load IBM Granite 3.3 2B Instruct Model
# ============================
model_name = "ibm-granite/granite-3.3-2b-instruct"

# FIX ‚Üí load slow tokenizer
tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)

# Load model
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.float16,
    device_map="auto"
)

# ============================
# TEXT GENERATION FUNCTION
# ============================
def generate_response(prompt):
    inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
    outputs = model.generate(
        **inputs,
        max_new_tokens=250,
        temperature=0.7,
        do_sample=True
    )
    return tokenizer.decode(outputs[0], skip_special_tokens=True)

# ============================
# MAIN APP LOGIC
# ============================
def ai_medical_system(name, age, gender, symptoms, medical_history, allergies):
    patient_info = f"""
    Patient Name: {name}
    Age: {age}
    Gender: {gender}
    Symptoms: {symptoms}
    Medical History: {medical_history}
    Allergies: {allergies}
    """

    # --- 1. Generate Prescription ---
    prescription_prompt = f"""
    You are a medical assistant AI.
    Create a safe medical prescription for the following patient.
    Avoid controlled substances.
    Be specific with dosage, timing, and precautions.

    {patient_info}

    Prescription:
    """
    prescription = generate_response(prescription_prompt)

    # --- 2. AI Feedback ---
    feedback_prompt = f"""
    Review this prescription for safety, potential risks, allergy conflicts, and warnings.
    Provide concise clinical feedback.

    Prescription:
    {prescription}
    """
    feedback = generate_response(feedback_prompt)

    return prescription, feedback


# ============================
# GRADIO UI
# ============================
with gr.Blocks(title="AI Medical Prescription System") as app:
    gr.Markdown("# üè• AI Medical Prescription System\nUsing IBM Granite 3.3 2B Instruct")

    with gr.Row():
        name = gr.Textbox(label="Patient Name")
        age = gr.Number(label="Age")
        gender = gr.Radio(["Male", "Female", "Other"], label="Gender")

    symptoms = gr.Textbox(label="Symptoms", lines=3)
    medical_history = gr.Textbox(label="Medical History", lines=3)
    allergies = gr.Textbox(label="Allergies", lines=2)

    generate_btn = gr.Button("Generate Prescription")

    prescription_output = gr.Textbox(label="AI-Generated Prescription", lines=10)
    feedback_output = gr.Textbox(label="AI Feedback & Safety Review", lines=10)

    generate_btn.click(
        ai_medical_system,
        inputs=[name, age, gender, symptoms, medical_history, allergies],
        outputs=[prescription_output, feedback_output]
    )

app.launch()



# ============================
# AI MEDICAL PRESCRIPTION PROJECT (FIXED TOKENIZER VERSION)
# Single-Cell Code for Google Colab
# Using IBM Granite 3.3 2B Instruct & Gradio UI
# ============================

!pip install -q transformers accelerate torch gradio sentencepiece

import gradio as gr
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# ============================
# Load IBM Granite 3.3 2B Instruct Model
# ============================
model_name = "ibm-granite/granite-3.3-2b-instruct"

# FIX ‚Üí load slow tokenizer
tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)

# Load model
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.float16,
    device_map="auto"
)

# ============================
# TEXT GENERATION FUNCTION
# ============================
def generate_response(prompt):
    inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
    outputs = model.generate(
        **inputs,
        max_new_tokens=250,
        temperature=0.7,
        do_sample=True
    )
    return tokenizer.decode(outputs[0], skip_special_tokens=True)

# ============================
# MAIN APP LOGIC
# ============================
def ai_medical_system(name, age, gender, symptoms, medical_history, allergies):
    patient_info = f"""
    Patient Name: {name}
    Age: {age}
    Gender: {gender}
    Symptoms: {symptoms}
    Medical History: {medical_history}
    Allergies: {allergies}
    """

    # --- 1. Generate Prescription ---
    prescription_prompt = f"""
    You are a medical assistant AI.
    Create a safe medical prescription for the following patient.
    Avoid controlled substances.
    Be specific with dosage, timing, and precautions.

    {patient_info}

    Prescription:
    """
    prescription = generate_response(prescription_prompt)

    # --- 2. AI Feedback ---
    feedback_prompt = f"""
    Review this prescription for safety, potential risks, allergy conflicts, and warnings.
    Provide concise clinical feedback.

    Prescription:
    {prescription}
    """
    feedback = generate_response(feedback_prompt)

    return prescription, feedback


# ============================
# GRADIO UI
# ============================
with gr.Blocks(title="AI Medical Prescription System") as app:
    gr.Markdown("# üè• AI Medical Prescription System\nUsing IBM Granite 3.3 2B Instruct")

    with gr.Row():
        name = gr.Textbox(label="Patient Name")
        age = gr.Number(label="Age")
        gender = gr.Radio(["Male", "Female", "Other"], label="Gender")

    symptoms = gr.Textbox(label="Symptoms", lines=3)
    medical_history = gr.Textbox(label="Medical History", lines=3)
    allergies = gr.Textbox(label="Allergies", lines=2)

    generate_btn = gr.Button("Generate Prescription")

    prescription_output = gr.Textbox(label="AI-Generated Prescription", lines=10)
    feedback_output = gr.Textbox(label="AI Feedback & Safety Review", lines=10)

    generate_btn.click(
        ai_medical_system,
        inputs=[name, age, gender, symptoms, medical_history, allergies],
        outputs=[prescription_output, feedback_output]
    )

app.launch()



# ============================================================
# AI MEDICAL PRESCRIPTION SYSTEM (Granite 3.3 2B, llama.cpp)
# ============================================================

!pip install -q gradio llama-cpp-python huggingface_hub

from llama_cpp import Llama
import gradio as gr
from huggingface_hub import hf_hub_download

# ============================================================
# Download the GGUF version of Granite 3.3 2B Instruct
# ============================================================

model_repo = "ibm-granite/granite-3.3-2b-instruct-GGUF"
model_file = "granite-3.3-2b-instruct-q4_k_m.gguf"   # small + fast

model_path = hf_hub_download(repo_id=model_repo, filename=model_file)

# ============================================================
# Load Model with llama.cpp
# ============================================================

llm = Llama(
    model_path=model_path,
    n_ctx=4096,
    n_threads=4,
    n_gpu_layers=20,     # GPU acceleration
)

# ============================================================
# Text generation function
# ============================================================

def generate(prompt):
    output = llm(
        prompt,
        max_tokens=250,
        temperature=0.7,
        stop=["</s>"]
    )
    return output["choices"][0]["text"].strip()

# ============================================================
# Medical System Logic
# ============================================================

def medical_system(name, age, gender, symptoms, history, allergies):

    patient_info = f"""
    Patient Name: {name}
    Age: {age}
    Gender: {gender}
    Symptoms: {symptoms}
    Medical History: {history}
    Allergies: {allergies}
    """

    # ---- Prescription ----
    pres_prompt = f"""
    You are an AI medical assistant.
    Create a safe medical prescription for the patient below.
    Avoid narcotics or controlled substances.
    Include dosage, timing, precautions, and lifestyle advice.

    {patient_info}

    Prescription:
    """

    prescription = generate(pres_prompt)

    # ---- Safety Feedback ----
    feedback_prompt = f"""
    Review the following prescription for safety issues,
    allergy conflicts, dosage problems, and patient risks.
    Be concise and medically responsible.

    Prescription:
    {prescription}

    Feedback:
    """

    feedback = generate(feedback_prompt)

    return prescription, feedback

# ============================================================
# GRADIO UI
# ============================================================

with gr.Blocks(title="AI Medical Prescription System") as app:
    gr.Markdown("# üè• AI Medical Prescription System (IBM Granite 3.3 2B)")

    with gr.Row():
        name = gr.Textbox(label="Patient Name")
        age = gr.Number(label="Age")
        gender = gr.Radio(["Male", "Female", "Other"], label="Gender")

    symptoms = gr.Textbox(label="Symptoms", lines=3)
    history = gr.Textbox(label="Medical History", lines=3)
    allergies = gr.Textbox(label="Allergies", lines=2)

    btn = gr.Button("Generate Prescription")

    out1 = gr.Textbox(label="AI Prescription", lines=8)
    out2 = gr.Textbox(label="AI Safety Feedback", lines=8)

    btn.click(
        fn=medical_system,
        inputs=[name, age, gender, symptoms, history, allergies],
        outputs=[out1, out2]
    )

app.launch()

